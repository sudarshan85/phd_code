{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercari Price Suggestion Challenge GBM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:41:08.340632Z",
     "start_time": "2019-12-15T19:41:08.067786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:41:08.393953Z",
     "start_time": "2019-12-15T19:41:08.343706Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import pdb\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.data_utils import set_two_splits\n",
    "from utils.plots import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:41:08.427223Z",
     "start_time": "2019-12-15T19:41:08.396639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': PosixPath('data'),\n",
       " 'workdir': PosixPath('data/workdir'),\n",
       " 'train_tsv': PosixPath('data/train.tsv'),\n",
       " 'test_tsv': PosixPath('data/test.tsv'),\n",
       " 'test2_tsv': PosixPath('data/test_stg2.tsv'),\n",
       " 'modeldir': PosixPath('data/workdir/models'),\n",
       " 'figdir': PosixPath('data/workdir/figures'),\n",
       " 'vectordir': PosixPath('data/workdir/vectordir')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from args import args\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:41:08.454141Z",
     "start_time": "2019-12-15T19:41:08.429144Z"
    }
   },
   "outputs": [],
   "source": [
    "save = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:45:22.400921Z",
     "start_time": "2019-12-14T20:45:22.382455Z"
    }
   },
   "outputs": [],
   "source": [
    "def wordcloud(fi, idx2tok, min_len=5, n_tokens=50):\n",
    "  idxs = np.argsort(fi)[-n_tokens:]\n",
    "  score = fi[idxs]/fi[idxs].sum()\n",
    "  tokens = [idx2tok[i] for i in idxs]\n",
    "  d = dict(zip(tokens, score))\n",
    "  return d, WordCloud(width=400, height=400, background_color='white', max_words=n_tokens, max_font_size=40, relative_scaling=0.5).generate_from_frequencies(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:41:18.051878Z",
     "start_time": "2019-12-15T19:41:14.296246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.397895</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.970292</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard\\nThis keyboar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.397895</td>\n",
       "      <td>AVA-VIV Blouse\\nAdorable top with a hint of la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.583519</td>\n",
       "      <td>Leather Horse Statues\\nNew with tags. Leather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.806662</td>\n",
       "      <td>24K GOLD plated rose\\nComplete with certificat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price                                               text\n",
       "0  2.397895              MLB Cincinnati Reds T Shirt Size XL\\n\n",
       "1  3.970292  Razer BlackWidow Chroma Keyboard\\nThis keyboar...\n",
       "2  2.397895  AVA-VIV Blouse\\nAdorable top with a hint of la...\n",
       "3  3.583519  Leather Horse Statues\\nNew with tags. Leather ...\n",
       "4  3.806662  24K GOLD plated rose\\nComplete with certificat..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = pd.read_csv(args.path/'train_df.csv', usecols=['text', 'price'])\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:41:20.943373Z",
     "start_time": "2019-12-15T19:41:19.996649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1462949, 3), (1243506, 2), (219443, 2), (1243506,), (219443,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 127\n",
    "df = set_two_splits(desc_df.copy(), 'valid', seed=seed)\n",
    "train_df = df.loc[df['split'] == 'train', ['text', 'price']]\n",
    "valid_df = df.loc[df['split'] == 'valid', ['text', 'price']]\n",
    "y_train = train_df['price']\n",
    "y_valid = valid_df['price']\n",
    "\n",
    "df.shape, train_df.shape, valid_df.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:45:27.505863Z",
     "start_time": "2019-12-14T20:45:27.487016Z"
    }
   },
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=60_000)\n",
    "# x_train = vectorizer.fit_transform(train_df['text'].values.astype('U'))\n",
    "# x_valid = vectorizer.transform(valid_df['text'].values.astype('U'))\n",
    "\n",
    "# with open(args.vectordir/'bigram_643.pkl', 'wb') as f:\n",
    "#   pickle.dump(vectorizer, f)\n",
    "#   pickle.dump(x_train, f)\n",
    "#   pickle.dump(x_valid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:41:32.106525Z",
     "start_time": "2019-12-15T19:41:30.092941Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(args.vectordir/f'bigram_{seed}.pkl', 'rb') as f:\n",
    "  vectorizer = pickle.load(f)\n",
    "  x_train = pickle.load(f)\n",
    "  x_valid = pickle.load(f)\n",
    "  \n",
    "idx2tok = {v: k for k, v in vectorizer.vocabulary_.items()}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:41:34.875972Z",
     "start_time": "2019-12-15T19:41:34.827354Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_valid = lgb.Dataset(x_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "lgb_params = {\n",
    "  'num_leaves': 400,\n",
    "  'learning_rate': 0.05,\n",
    "  'feature_fraction': 0.9,\n",
    "  'bagging_fraction': 0.7,\n",
    "  'bagging_freq': 5,\n",
    "  'metric': 'rmse',\n",
    "  'num_threads': 32,\n",
    "  'max_bin': 32,\n",
    "  'objective': 'regression',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:42:01.864918Z",
     "start_time": "2019-12-15T19:41:45.821825Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 0.718447\tvalid_1's rmse: 0.717037\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 0.709666\tvalid_1's rmse: 0.708398\n",
      "[3]\ttraining's rmse: 0.700485\tvalid_1's rmse: 0.69931\n",
      "[4]\ttraining's rmse: 0.692408\tvalid_1's rmse: 0.691331\n",
      "[5]\ttraining's rmse: 0.684889\tvalid_1's rmse: 0.683967\n",
      "[6]\ttraining's rmse: 0.67754\tvalid_1's rmse: 0.676764\n",
      "[7]\ttraining's rmse: 0.671449\tvalid_1's rmse: 0.670767\n",
      "[8]\ttraining's rmse: 0.66505\tvalid_1's rmse: 0.664502\n",
      "[9]\ttraining's rmse: 0.659128\tvalid_1's rmse: 0.658683\n",
      "[10]\ttraining's rmse: 0.652844\tvalid_1's rmse: 0.652491\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttraining's rmse: 0.652844\tvalid_1's rmse: 0.652491\n"
     ]
    }
   ],
   "source": [
    "gbm = lgb.train(lgb_params, lgb_train, num_boost_round=10, valid_sets=[lgb_train, lgb_valid], early_stopping_rounds=10, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:42:02.830797Z",
     "start_time": "2019-12-15T19:42:02.707383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.652"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gbm.predict(x_valid)\n",
    "np.round(np.sqrt(mean_squared_error(y_valid, preds)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T00:53:55.541309Z",
     "start_time": "2019-12-15T00:53:54.179284Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "d, wc = wordcloud(gbm.feature_importance(importance_type='gain'), idx2tok, min_len=5, n_tokens=500)\n",
    "ax.imshow(wc)\n",
    "ax.axis('off')\n",
    "\n",
    "if save:\n",
    "  fig.savefig(args.figdir/'desc_wc.pdf', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T18:41:31.223122Z",
     "start_time": "2019-10-27T18:41:27.331682Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(args.path/'train_df.csv', usecols=['text', 'price'])\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T18:43:06.681682Z",
     "start_time": "2019-10-27T18:41:31.225486Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=60_000)\n",
    "x_train = vectorizer.fit_transform(train_df['text'].values.astype('U'))\n",
    "\n",
    "with open(args.vectordir/'default_bi_all.pkl', 'wb') as f:\n",
    "  pickle.dump(vectorizer, f)\n",
    "  pickle.dump(x_train, f)\n",
    "  \n",
    "y_train = train_df['price']\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T18:43:08.986485Z",
     "start_time": "2019-10-27T18:43:06.685928Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(args.vectordir/'default_bi_all.pkl', 'rb') as f:\n",
    "  vectorizer = pickle.load(f)\n",
    "  x_train = pickle.load(f)\n",
    "\n",
    "idx2tok = {v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T18:43:09.006793Z",
     "start_time": "2019-10-27T18:43:08.988112Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_params = {\n",
    "  'num_leaves': 400,\n",
    "  'learning_rate': 0.05,\n",
    "  'feature_fraction': 0.9,\n",
    "  'bagging_fraction': 0.7,\n",
    "  'bagging_freq': 5,\n",
    "  'metric': 'rmse',\n",
    "  'num_threads': 32,\n",
    "  'max_bin': 32,\n",
    "  'objective': 'regression',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:09:13.227080Z",
     "start_time": "2019-10-27T18:43:09.008362Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm = lgb.train(lgb_params, lgb_train, num_boost_round=1000, valid_sets=[lgb_train], early_stopping_rounds=10, verbose_eval=True)\n",
    "pickle.dump(gbm, (args.modeldir/'gbm_desc_all.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:09:15.865283Z",
     "start_time": "2019-10-27T19:09:13.230714Z"
    }
   },
   "outputs": [],
   "source": [
    "gbm = pickle.load((args.modeldir/'gbm_desc_all.pkl').open('rb'))\n",
    "\n",
    "with open(args.vectordir/'default_bi_all.pkl', 'rb') as f:\n",
    "  vectorizer = pickle.load(f)\n",
    "  x_train = pickle.load(f)\n",
    "\n",
    "idx2tok = {v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:09:18.191818Z",
     "start_time": "2019-10-27T19:09:15.866636Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "d, wc = wordcloud(gbm.feature_importance(importance_type='gain'), idx2tok, min_len=5, n_tokens=500)\n",
    "ax.imshow(wc)\n",
    "ax.axis('off')\n",
    "fig.savefig(args.figdir/'gbm_desc_wc.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:10:10.281481Z",
     "start_time": "2019-10-27T19:09:18.195565Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(args.path/'test_df.csv', usecols=['test_id', 'text'])\n",
    "x_test = vectorizer.transform(test_df['text'].values.astype('U'))\n",
    "preds = pd.DataFrame({'test_id': test_df['test_id'], 'price': np.expm1(gbm.predict(x_test))})\n",
    "preds.to_csv(args.path/'gbm_desc_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:14:32.068580Z",
     "start_time": "2019-10-27T19:10:10.284005Z"
    }
   },
   "outputs": [],
   "source": [
    "test2_df = pd.read_csv(args.path/'test2_df.csv', usecols=['test_id', 'text'])\n",
    "x_test2 = vectorizer.transform(test2_df['text'].values.astype('U'))\n",
    "preds_test2 = pd.DataFrame({'test_id': test2_df['test_id'], 'price': np.expm1(gbm.predict(x_test2))})\n",
    "preds_test2.to_csv(args.path/'gbm_desc_submission_stg2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
