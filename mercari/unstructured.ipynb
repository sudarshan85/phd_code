{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercari Price Suggestion Challenge GBM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T18:01:11.818752Z",
     "start_time": "2019-12-15T18:01:11.806554Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T18:01:12.554085Z",
     "start_time": "2019-12-15T18:01:11.820213Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import pdb\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.data_utils import set_two_splits\n",
    "from utils.plots import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T18:02:07.805691Z",
     "start_time": "2019-12-15T18:02:07.786949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': PosixPath('data'),\n",
       " 'workdir': PosixPath('data/workdir'),\n",
       " 'train_tsv': PosixPath('data/train.tsv'),\n",
       " 'test_tsv': PosixPath('data/test.tsv'),\n",
       " 'test2_tsv': PosixPath('data/test_stg2.tsv'),\n",
       " 'modeldir': PosixPath('data/workdir/models'),\n",
       " 'figdir': PosixPath('data/workdir/figures')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from args import args\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T17:57:53.296376Z",
     "start_time": "2019-12-15T17:57:53.272322Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T17:57:57.033926Z",
     "start_time": "2019-12-15T17:57:53.297877Z"
    }
   },
   "outputs": [],
   "source": [
    "desc_df = pd.read_csv(args.path/'train_df.csv', usecols=['text', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T17:59:53.355840Z",
     "start_time": "2019-12-15T17:57:57.035225Z"
    }
   },
   "outputs": [],
   "source": [
    "for seed in trange(127, 137):  \n",
    "  df = set_two_splits(desc_df.copy(), 'valid', seed=seed)\n",
    "  train_df = df.loc[df['split'] == 'train', ['text', 'price']]\n",
    "  valid_df = df.loc[df['split'] == 'valid', ['text', 'price']]\n",
    "  \n",
    "  vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=60_000)\n",
    "  x_train = vectorizer.fit_transform(train_df['text'].values.astype('U'))\n",
    "  x_valid = vectorizer.transform(valid_df['text'].values.astype('U'))\n",
    "\n",
    "  with open(args.vectordir/f'bigram_{seed}.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "    pickle.dump(x_train, f)\n",
    "    pickle.dump(x_valid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T00:54:24.784514Z",
     "start_time": "2019-12-15T00:54:24.738870Z"
    }
   },
   "outputs": [],
   "source": [
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:45:22.400921Z",
     "start_time": "2019-12-14T20:45:22.382455Z"
    }
   },
   "outputs": [],
   "source": [
    "def wordcloud(fi, idx2tok, min_len=5, n_tokens=50):\n",
    "  idxs = np.argsort(fi)[-n_tokens:]\n",
    "  score = fi[idxs]/fi[idxs].sum()\n",
    "  tokens = [idx2tok[i] for i in idxs]\n",
    "  d = dict(zip(tokens, score))\n",
    "  return d, WordCloud(width=400, height=400, background_color='white', max_words=n_tokens, max_font_size=40, relative_scaling=0.5).generate_from_frequencies(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:45:26.489249Z",
     "start_time": "2019-12-14T20:45:22.403466Z"
    }
   },
   "outputs": [],
   "source": [
    "desc_df = pd.read_csv(args.path/'train_df.csv', usecols=['text', 'price'])\n",
    "desc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:45:27.485578Z",
     "start_time": "2019-12-14T20:45:26.490881Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 643\n",
    "df = set_two_splits(desc_df.copy(), 'valid', seed=seed)\n",
    "train_df = df.loc[df['split'] == 'train', ['text', 'price']]\n",
    "valid_df = df.loc[df['split'] == 'valid', ['text', 'price']]\n",
    "y_train = train_df['price']\n",
    "y_valid = valid_df['price']\n",
    "\n",
    "df.shape, train_df.shape, valid_df.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:45:27.505863Z",
     "start_time": "2019-12-14T20:45:27.487016Z"
    }
   },
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=60_000)\n",
    "# x_train = vectorizer.fit_transform(train_df['text'].values.astype('U'))\n",
    "# x_valid = vectorizer.transform(valid_df['text'].values.astype('U'))\n",
    "\n",
    "# with open(args.vectordir/'bigram_643.pkl', 'wb') as f:\n",
    "#   pickle.dump(vectorizer, f)\n",
    "#   pickle.dump(x_train, f)\n",
    "#   pickle.dump(x_valid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:45:29.773061Z",
     "start_time": "2019-12-14T20:45:27.506873Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(args.vectordir/'bigram_643.pkl', 'rb') as f:\n",
    "  vectorizer = pickle.load(f)\n",
    "  x_train = pickle.load(f)\n",
    "  x_valid = pickle.load(f)\n",
    "  \n",
    "idx2tok = {v: k for k, v in vectorizer.vocabulary_.items()}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:45:29.796516Z",
     "start_time": "2019-12-14T20:45:29.775113Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_valid = lgb.Dataset(x_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "lgb_params = {\n",
    "  'num_leaves': 400,\n",
    "  'learning_rate': 0.05,\n",
    "  'feature_fraction': 0.9,\n",
    "  'bagging_fraction': 0.7,\n",
    "  'bagging_freq': 5,\n",
    "  'metric': 'rmse',\n",
    "  'num_threads': 32,\n",
    "  'max_bin': 32,\n",
    "  'objective': 'regression',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:00:02.310435Z",
     "start_time": "2019-12-14T20:45:29.797673Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm = lgb.train(lgb_params, lgb_train, num_boost_round=600, valid_sets=[lgb_train, lgb_valid], early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T00:53:55.541309Z",
     "start_time": "2019-12-15T00:53:54.179284Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "d, wc = wordcloud(gbm.feature_importance(importance_type='gain'), idx2tok, min_len=5, n_tokens=500)\n",
    "ax.imshow(wc)\n",
    "ax.axis('off')\n",
    "\n",
    "if save:\n",
    "  fig.savefig(args.figdir/'desc_wc.pdf', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T00:54:50.360708Z",
     "start_time": "2019-12-15T00:54:47.080694Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = gbm.predict(x_valid)\n",
    "np.round(np.sqrt(mean_squared_error(y_valid, preds)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T18:41:31.223122Z",
     "start_time": "2019-10-27T18:41:27.331682Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(args.path/'train_df.csv', usecols=['text', 'price'])\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T18:43:06.681682Z",
     "start_time": "2019-10-27T18:41:31.225486Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=60_000)\n",
    "x_train = vectorizer.fit_transform(train_df['text'].values.astype('U'))\n",
    "\n",
    "with open(args.vectordir/'default_bi_all.pkl', 'wb') as f:\n",
    "  pickle.dump(vectorizer, f)\n",
    "  pickle.dump(x_train, f)\n",
    "  \n",
    "y_train = train_df['price']\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T18:43:08.986485Z",
     "start_time": "2019-10-27T18:43:06.685928Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(args.vectordir/'default_bi_all.pkl', 'rb') as f:\n",
    "  vectorizer = pickle.load(f)\n",
    "  x_train = pickle.load(f)\n",
    "\n",
    "idx2tok = {v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T18:43:09.006793Z",
     "start_time": "2019-10-27T18:43:08.988112Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_params = {\n",
    "  'num_leaves': 400,\n",
    "  'learning_rate': 0.05,\n",
    "  'feature_fraction': 0.9,\n",
    "  'bagging_fraction': 0.7,\n",
    "  'bagging_freq': 5,\n",
    "  'metric': 'rmse',\n",
    "  'num_threads': 32,\n",
    "  'max_bin': 32,\n",
    "  'objective': 'regression',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:09:13.227080Z",
     "start_time": "2019-10-27T18:43:09.008362Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm = lgb.train(lgb_params, lgb_train, num_boost_round=1000, valid_sets=[lgb_train], early_stopping_rounds=10, verbose_eval=True)\n",
    "pickle.dump(gbm, (args.modeldir/'gbm_desc_all.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:09:15.865283Z",
     "start_time": "2019-10-27T19:09:13.230714Z"
    }
   },
   "outputs": [],
   "source": [
    "gbm = pickle.load((args.modeldir/'gbm_desc_all.pkl').open('rb'))\n",
    "\n",
    "with open(args.vectordir/'default_bi_all.pkl', 'rb') as f:\n",
    "  vectorizer = pickle.load(f)\n",
    "  x_train = pickle.load(f)\n",
    "\n",
    "idx2tok = {v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:09:18.191818Z",
     "start_time": "2019-10-27T19:09:15.866636Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "d, wc = wordcloud(gbm.feature_importance(importance_type='gain'), idx2tok, min_len=5, n_tokens=500)\n",
    "ax.imshow(wc)\n",
    "ax.axis('off')\n",
    "fig.savefig(args.figdir/'gbm_desc_wc.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:10:10.281481Z",
     "start_time": "2019-10-27T19:09:18.195565Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(args.path/'test_df.csv', usecols=['test_id', 'text'])\n",
    "x_test = vectorizer.transform(test_df['text'].values.astype('U'))\n",
    "preds = pd.DataFrame({'test_id': test_df['test_id'], 'price': np.expm1(gbm.predict(x_test))})\n",
    "preds.to_csv(args.path/'gbm_desc_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T19:14:32.068580Z",
     "start_time": "2019-10-27T19:10:10.284005Z"
    }
   },
   "outputs": [],
   "source": [
    "test2_df = pd.read_csv(args.path/'test2_df.csv', usecols=['test_id', 'text'])\n",
    "x_test2 = vectorizer.transform(test2_df['text'].values.astype('U'))\n",
    "preds_test2 = pd.DataFrame({'test_id': test2_df['test_id'], 'price': np.expm1(gbm.predict(x_test2))})\n",
    "preds_test2.to_csv(args.path/'gbm_desc_submission_stg2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
