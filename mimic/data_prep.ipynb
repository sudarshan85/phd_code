{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC Notes and Structured Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:24.994276Z",
     "start_time": "2019-12-19T00:56:24.960395Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:26.672701Z",
     "start_time": "2019-12-19T00:56:25.001890Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:26.706413Z",
     "start_time": "2019-12-19T00:56:26.675546Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "workdir = path/'workdir'\n",
    "figdir = workdir/'figures'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:26.735274Z",
     "start_time": "2019-12-19T00:56:26.708658Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_name(col_name):\n",
    "  if '(' not in col_name:\n",
    "    return col_name\n",
    "  cols = literal_eval(col_name)\n",
    "  return f'{cols[0]}_{cols[1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:26.765700Z",
     "start_time": "2019-12-19T00:56:26.736862Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_interval(x):\n",
    "  if pd.isnull(x):\n",
    "    return -1\n",
    "  \n",
    "  if 0 < x <= 1:\n",
    "    return 0\n",
    "  elif 1 < x <= 2:\n",
    "    return 1\n",
    "  elif 2 < x <= 3:\n",
    "    return 2\n",
    "  elif 3 < x <= 4:\n",
    "    return 3\n",
    "  elif 4 < x <= 5:\n",
    "    return 4\n",
    "  elif 5 < x <= 6:\n",
    "    return 5\n",
    "  elif 6 < x <= 7:\n",
    "    return 6\n",
    "  elif 7 < x <= 8:\n",
    "    return 7\n",
    "  elif 8 < x <= 9:\n",
    "    return 8\n",
    "  elif 9 < x <= 10:\n",
    "    return 9\n",
    "  elif 10 < x <= 11:\n",
    "    return 10\n",
    "  elif 11 < x <= 12:\n",
    "    return 11\n",
    "  elif 12 < x <= 13:\n",
    "    return 12\n",
    "  elif 13 < x <= 14:\n",
    "    return 13\n",
    "  elif 14 < x <= 15:\n",
    "    return 14\n",
    "  else:\n",
    "    return 15\n",
    "\n",
    "def icu_adm_label(x):\n",
    "  if 0 <= x <= 1:\n",
    "    return -1 # unused notes due to data leakage\n",
    "  elif 1 < x <= 3:\n",
    "    return 1 # imminent ICU admission\n",
    "  elif 3 < x <= 5:\n",
    "    return -1 # unused notes due to data leakage\n",
    "  else:\n",
    "    return 0 # delayed ICU admission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:34.341687Z",
     "start_time": "2019-12-19T00:56:30.882878Z"
    }
   },
   "outputs": [],
   "source": [
    "notes_df = pd.read_csv(path/'unstructured_raw.csv', parse_dates=['intime', 'admittime', 'charttime'])\n",
    "notes_df.drop_duplicates(inplace=True)\n",
    "\n",
    "vitals_df = pd.read_csv(path/'structured_raw.csv', parse_dates=['charttime'])\n",
    "vitals_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:34.389890Z",
     "start_time": "2019-12-19T00:56:34.343845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encounters that definitely have structured vitals data: 14150\n",
      "Number of encounters that definitely have clinical notes: 12932\n",
      "Number of encounters that have both vitals and clinical notes: 8254\n"
     ]
    }
   ],
   "source": [
    "notes_hadms = notes_df['hadm_id'].unique()\n",
    "vitals_hadms = vitals_df['hadm_id'].unique()\n",
    "\n",
    "# Extract common `hadm_id` and filter out those that do not appear in both dfs\n",
    "common_hadms = set(vitals_df['hadm_id'].unique()).intersection(notes_df['hadm_id'].unique())\n",
    "\n",
    "print(f\"Number of encounters that definitely have structured vitals data: {len(vitals_hadms)}\")\n",
    "print(f\"Number of encounters that definitely have clinical notes: {len(notes_hadms)}\")\n",
    "print(f\"Number of encounters that have both vitals and clinical notes: {len(common_hadms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:34.572190Z",
     "start_time": "2019-12-19T00:56:34.391744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1463808, 10), (64457, 7))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_common = notes_df[notes_df['hadm_id'].isin(common_hadms)].reset_index(drop=True)\n",
    "vitals_common = vitals_df[vitals_df['hadm_id'].isin(common_hadms)].reset_index(drop=True)\n",
    "\n",
    "# sanity check\n",
    "s, n = set(vitals_common['hadm_id'].unique()), set(notes_common['hadm_id'].unique())\n",
    "assert(s.symmetric_difference(n) == set())\n",
    "\n",
    "vitals_common.shape, notes_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:39.150444Z",
     "start_time": "2019-12-19T00:56:34.573642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53270, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_common['note'] = notes_common['category'].str.cat(notes_common['description'], sep='\\n')\n",
    "notes_common['note'] = notes_common['note'].str.cat(notes_common['text'], sep='\\n')\n",
    "notes_common.drop(columns=['category', 'description', 'text'], inplace=True) \n",
    "\n",
    "notes_common = pd.DataFrame(notes_common.groupby(['hadm_id', 'intime', 'admittime', 'charttime'])['note'].apply('\\n'.join)).reset_index()\n",
    "notes_common['category'] = notes_common['note'].apply(lambda x: x.split('\\n')[0])\n",
    "notes_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:50.655623Z",
     "start_time": "2019-12-19T00:56:39.151982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270288, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove redundant info by filling in each time column with the value of the var\n",
    "vitals_common = vitals_common.groupby(['hadm_id','charttime']).sum(min_count = 1).reset_index()\n",
    "# Groupby ffill \n",
    "vitals_common = vitals_common.groupby(['hadm_id'], as_index=False).apply(lambda group: group.ffill())\n",
    "# Groupby bfill \n",
    "vitals_common = vitals_common.groupby(['hadm_id'], as_index=False).apply(lambda group: group.bfill())\n",
    "vitals_common = vitals_common.fillna(vitals_common.median())\n",
    "vitals_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T00:56:55.554513Z",
     "start_time": "2019-12-19T00:56:50.656967Z"
    }
   },
   "outputs": [],
   "source": [
    "notes_common.to_csv(path/'unstructured_notes_proc.csv', index=False)\n",
    "vitals_common.to_csv(path/'structured_vitals_proc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Compute Statistics Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:33:14.920968Z",
     "start_time": "2019-12-18T22:33:14.511782Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vitals_common = pd.read_csv(path/'structured_vitals_proc.csv', parse_dates=['charttime'])\n",
    "vitals_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:33:15.765402Z",
     "start_time": "2019-12-18T22:33:15.703275Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vitals_common.groupby('hadm_id').size(), columns=['size']).reset_index()\n",
    "hadms = x.loc[(x['size'] >= 10) & (x['size'] <= 20)].sample(5)['hadm_id'].tolist()\n",
    "x.loc[x['hadm_id'].isin(hadms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:33:16.886923Z",
     "start_time": "2019-12-18T22:33:16.835634Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_subset = vitals_common.loc[(vitals_common['hadm_id'].isin(hadms))].reset_index(drop=True)\n",
    "print(dev_subset.shape)\n",
    "print(dev_subset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:33:17.557350Z",
     "start_time": "2019-12-18T22:33:17.512582Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var_cols = dev_subset.columns[2:]\n",
    "print(len(var_cols))\n",
    "running_stats = ['min', 'mean', 'median', 'std', 'max']\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:33:18.612611Z",
     "start_time": "2019-12-18T22:33:18.320717Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for hadm_id, group_df in tqdm(dev_subset.groupby('hadm_id'), desc='Encounters'):\n",
    "  df = group_df.copy()\n",
    "  var_df = df[var_cols].reset_index(drop=True) # save the original vals for later\n",
    "  \n",
    "  df.set_index('charttime', inplace=True) # set charttime as index for rolling 24h\n",
    "  stats_df = df[var_cols].rolling('24h').agg(running_stats)\n",
    "  \n",
    "  df = pd.DataFrame(stats_df.to_records()) # flatten the resulting dataframe\n",
    "  df.insert(loc=1, column='hadm_id', value=hadm_id)\n",
    "  \n",
    "  df.rename(columns=change_name, inplace=True) # rename columns\n",
    "  df = pd.concat([df, var_df], axis=1) # add the original vals back\n",
    "  \n",
    "  # reorder vars such that the columns are var, var_stat...\n",
    "  stats_cols = df.columns[2:]\n",
    "  all_cols = []\n",
    "  for var in var_cols:\n",
    "    all_cols.append(var)\n",
    "    for stat in stats_cols:\n",
    "      if f'{var}_' in stat:\n",
    "        all_cols.append(stat)\n",
    "        \n",
    "  order = list(df.columns[:2]) + all_cols\n",
    "  df = df[order]\n",
    "  dfs.append(df)\n",
    "\n",
    "dev_subset_stats = pd.concat(dfs)\n",
    "dev_subset_stats.reset_index(drop=True, inplace=True)\n",
    "dev_subset_stats['charttime'] = pd.to_datetime(dev_subset_stats['charttime'])\n",
    "\n",
    "std_cols = [col for col in dev_subset_stats.columns if 'std' in col]\n",
    "dev_subset_stats[std_cols] = dev_subset_stats[std_cols].fillna(0)\n",
    "\n",
    "dev_subset_stats = dev_subset_stats[['hadm_id', 'charttime'] + list(dev_subset_stats.columns[2:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:33:18.887521Z",
     "start_time": "2019-12-18T22:33:18.857674Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(dev_subset_stats.shape)\n",
    "dev_subset_stats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:01:46.799664Z",
     "start_time": "2019-12-19T01:01:44.065913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270288, 50) (53270, 5) 8254 8254\n"
     ]
    }
   ],
   "source": [
    "notes_common = pd.read_csv(path/'unstructured_notes_proc.csv', parse_dates=['intime', 'admittime', 'charttime'])\n",
    "notes_common.drop(columns=['category'], inplace=True)\n",
    "\n",
    "vitals_common_stats = pd.read_csv(path/'structured_vitals_stats.csv', parse_dates=['charttime'])\n",
    "\n",
    "pickle.dump(list(vitals_common_stats.columns[2:]), open(path/'str_cols.pkl', 'wb'))\n",
    "\n",
    "print(vitals_common_stats.shape, notes_common.shape, vitals_common_stats['hadm_id'].nunique(), notes_common['hadm_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Merge Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:10.344261Z",
     "start_time": "2019-12-18T22:38:10.295458Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main = ['hadm_id', 'charttime']\n",
    "sub1 = ['hr', 'hr_max', 'temp', 'temp_min', 'glucose', 'glucose_std', 'map', 'map_median']\n",
    "sub2 = ['admittime', 'intime', 'note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:10.521305Z",
     "start_time": "2019-12-18T22:38:10.448139Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(notes_common.groupby('hadm_id').size(), columns=['size']).reset_index()\n",
    "hadms = x.loc[(x['size'] >= 2) & (x['size'] <= 15)].sample(5)['hadm_id'].tolist()\n",
    "\n",
    "subset_stats = vitals_common_stats.loc[(vitals_common_stats['hadm_id'].isin(hadms))][main + sub1].copy().reset_index(drop=True)\n",
    "\n",
    "subset_notes = notes_common.loc[(notes_common['hadm_id'].isin(hadms))][main + sub2].copy().reset_index(drop=True)\n",
    "subset_stats.shape, subset_stats['hadm_id'].nunique(), subset_notes.shape, subset_notes['hadm_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:10.661152Z",
     "start_time": "2019-12-18T22:38:10.608832Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(subset_stats.groupby('hadm_id').size(), columns=['size']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:11.112122Z",
     "start_time": "2019-12-18T22:38:11.060392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(subset_notes.groupby('hadm_id').size(), columns=['size']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:12.072722Z",
     "start_time": "2019-12-18T22:38:11.995340Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_stats.sort_values(by='charttime', inplace=True)\n",
    "subset_stats.reset_index(inplace=True, drop=True)\n",
    "\n",
    "subset_notes.sort_values(by='charttime', inplace=True)\n",
    "subset_notes.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df = pd.merge_asof(subset_notes, subset_stats, left_on='charttime', right_on='charttime', by='hadm_id')\n",
    "\n",
    "cols = ['hr', 'hr_max', 'temp', 'temp_min', 'glucose', 'glucose_std', 'map', 'map_median']\n",
    "\n",
    "df = df.groupby(['hadm_id'], as_index=False).apply(lambda group: group.bfill())\n",
    "df[cols] = df[cols].fillna(df[cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:12.396116Z",
     "start_time": "2019-12-18T22:38:12.353190Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:12.802282Z",
     "start_time": "2019-12-18T22:38:12.758336Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "print(hadms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:12.983933Z",
     "start_time": "2019-12-18T22:38:12.925370Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_stats[subset_stats['hadm_id'] == hadms[i]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:13.235091Z",
     "start_time": "2019-12-18T22:38:13.180526Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_notes[subset_notes['hadm_id'] == hadms[i]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:14.305458Z",
     "start_time": "2019-12-18T22:38:14.240381Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df['hadm_id'] == hadms[i]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:38:15.630531Z",
     "start_time": "2019-12-18T22:38:15.584769Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:01:54.707122Z",
     "start_time": "2019-12-19T01:01:47.521384Z"
    }
   },
   "outputs": [],
   "source": [
    "vitals_common_stats.sort_values(by='charttime', inplace=True)\n",
    "vitals_common_stats.reset_index(inplace=True, drop=True)\n",
    "\n",
    "notes_common.sort_values(by='charttime', inplace=True)\n",
    "notes_common.reset_index(inplace=True, drop=True)\n",
    "\n",
    "mm_notes_vitals = pd.merge_asof(notes_common, vitals_common_stats, left_on='charttime', right_on='charttime', by='hadm_id')\n",
    "\n",
    "str_cols = pickle.load(open(path/'str_cols.pkl', 'rb'))\n",
    "\n",
    "mm_notes_vitals = mm_notes_vitals.groupby(['hadm_id'], as_index=False).apply(lambda group: group.bfill())\n",
    "mm_notes_vitals[str_cols] = mm_notes_vitals[str_cols].fillna(mm_notes_vitals[str_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:01:54.747328Z",
     "start_time": "2019-12-19T01:01:54.708874Z"
    }
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(mm_notes_vitals.isna().sum(), columns=['sum']).reset_index()\n",
    "assert(x['sum'].sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:01:59.468343Z",
     "start_time": "2019-12-19T01:01:54.748805Z"
    }
   },
   "outputs": [],
   "source": [
    "mm_notes_vitals.to_csv(path/'mm_notes_vitals_proc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:02:02.575211Z",
     "start_time": "2019-12-19T01:02:00.175672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53270, 5) (53270, 53)\n"
     ]
    }
   ],
   "source": [
    "notes_common = pd.read_csv(path/'unstructured_notes_proc.csv', parse_dates=['intime', 'admittime', 'charttime'])\n",
    "notes_common.drop(columns=['category'], inplace=True)\n",
    "\n",
    "mm_notes_vitals = pd.read_csv(path/'mm_notes_vitals_proc.csv', parse_dates=['intime', 'admittime', 'charttime'])\n",
    "\n",
    "print(notes_common.shape, mm_notes_vitals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:02:02.739290Z",
     "start_time": "2019-12-19T01:02:02.576753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53270, 9) 8254 (53270, 57) 8254\n"
     ]
    }
   ],
   "source": [
    "notes_common['admit_to_icu'] = (notes_common['intime'] - notes_common['admittime'])/np.timedelta64(1, 'D')\n",
    "notes_common['chart_to_icu'] = (notes_common['intime'] - notes_common['charttime'])/np.timedelta64(1, 'D')\n",
    "notes_common['interval'] = notes_common['chart_to_icu'].apply(data_interval)\n",
    "notes_common['imi_adm_label'] = notes_common['interval'].apply(icu_adm_label)\n",
    "\n",
    "mm_notes_vitals['admit_to_icu'] = (mm_notes_vitals['intime'] - mm_notes_vitals['admittime'])/np.timedelta64(1, 'D')\n",
    "mm_notes_vitals['chart_to_icu'] = (mm_notes_vitals['intime'] - mm_notes_vitals['charttime'])/np.timedelta64(1, 'D')\n",
    "mm_notes_vitals['interval'] = mm_notes_vitals['chart_to_icu'].apply(data_interval)\n",
    "mm_notes_vitals['imi_adm_label'] = mm_notes_vitals['interval'].apply(icu_adm_label)\n",
    "\n",
    "print(notes_common.shape, notes_common['hadm_id'].nunique(), mm_notes_vitals.shape, mm_notes_vitals['hadm_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:02:10.251607Z",
     "start_time": "2019-12-19T01:02:02.740825Z"
    }
   },
   "outputs": [],
   "source": [
    "notes_common.to_csv(path/'modelready_unstructured.csv', index=False)\n",
    "mm_notes_vitals.to_csv(path/'modelready_mm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cohort: **notes_all**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Read in all **notes_all** and subset it to get all the data with label not equal to -1 (only data used for modeling). Then get the unique ``hadm_id``'s within that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:34:57.639816Z",
     "start_time": "2019-11-08T11:34:55.210139Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "notes_df = pd.read_csv(path/'notes_all_proc.csv', parse_dates=['intime', 'admittime', 'ne_charttime'])\n",
    "model_notes_df = notes_df[notes_df['imi_adm_label'] != -1].reset_index(drop=True)\n",
    "hadms = model_notes_df['hadm_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Subset the **notes_cohort** to get details of only those encountered that are used for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:34:57.701506Z",
     "start_time": "2019-11-08T11:34:57.641856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "notes_cohort = pd.read_csv(path/'notes_all_cohort.csv')\n",
    "notes_cohort = notes_cohort[notes_cohort['hadm_id'].isin(hadms)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:34:57.723224Z",
     "start_time": "2019-11-08T11:34:57.703132Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_eth(eth):\n",
    "  eth = eth.lower()\n",
    "  if 'white' in eth:\n",
    "    return 'white'\n",
    "  elif 'black' in eth:\n",
    "    return 'black'\n",
    "  elif 'hispanic' in eth:\n",
    "    return 'hispanic'\n",
    "  elif 'asian' in eth:\n",
    "    return 'asian'\n",
    "  else:\n",
    "    return 'other'\n",
    "\n",
    "notes_cohort['ethnicity'] = notes_cohort['ethnicity'].apply(group_eth)\n",
    "notes_cohort.loc[notes_cohort['admission_age'] > 100, 'admission_age'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:34:57.755577Z",
     "start_time": "2019-11-08T11:34:57.724741Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of patients in notes cohort: {notes_cohort['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:34:57.777448Z",
     "start_time": "2019-11-08T11:34:57.757106Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = notes_cohort.groupby('expire_flag')['subject_id'].nunique().to_numpy()\n",
    "print(f\"Mortality in notes cohort: {g[1]} ({(g[1]/g.sum())*100:0.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:34:57.796887Z",
     "start_time": "2019-11-08T11:34:57.778932Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = notes_cohort.groupby('gender')['subject_id'].nunique().to_numpy()\n",
    "print(f\"Males in notes cohort: {g[1]} ({(g[1]/g.sum())*100:0.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:34:57.845698Z",
     "start_time": "2019-11-08T11:34:57.798152Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Mean:{notes_cohort.groupby('subject_id')['admission_age'].first().mean():0.1f}\")\n",
    "print(f\"STD:{notes_cohort.groupby('subject_id')['admission_age'].first().std():0.1f}\")\n",
    "print(f\"25th percentile:{notes_cohort.groupby('subject_id')['admission_age'].first().quantile(0.25):0.1f}\")\n",
    "print(f\"75th percentile:{notes_cohort.groupby('subject_id')['admission_age'].first().quantile(0.75):0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:34:57.886585Z",
     "start_time": "2019-11-08T11:34:57.847471Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = pd.DataFrame(notes_cohort.groupby('admission_type')['hadm_id'].nunique()).reset_index()\n",
    "g.columns = ['encounter_type', 'count']\n",
    "g['pct'] = np.round((g['count']/g['count'].sum() * 100), 1)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:34:57.911379Z",
     "start_time": "2019-11-08T11:34:57.888169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = pd.DataFrame(notes_cohort.groupby('ethnicity')['subject_id'].nunique()).reset_index()\n",
    "g.columns = ['ethnicity', 'count']\n",
    "g['pct'] = np.round((g['count']/g['count'].sum() * 100), 1)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Notes Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:35:02.943214Z",
     "start_time": "2019-11-08T11:35:01.777594Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "notes_df = pd.read_csv(path/'notes_all_proc.csv', parse_dates=['intime', 'admittime', 'ne_charttime'])\n",
    "model_notes_df = notes_df[notes_df['imi_adm_label'] != -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:35:04.907623Z",
     "start_time": "2019-11-08T11:35:04.729899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Encounter time to ICU Admission for model cohort:\")\n",
    "print(f\"Mean:{model_notes_df['admit_to_icu'].mean():0.1f}\")\n",
    "print(f\"STD:{model_notes_df['admit_to_icu'].std():0.1f}\")\n",
    "print(f\"25th percentile:{model_notes_df['admit_to_icu'].quantile(0.25):0.1f}\")\n",
    "print(f\"75th percentile:{model_notes_df['admit_to_icu'].quantile(0.75):0.1f}\")\n",
    "print(\"Encounter time to ICU Admission for notes cohort:\")\n",
    "print(f\"Mean:{notes_df['admit_to_icu'].mean():0.1f}\")\n",
    "print(f\"STD:{notes_df['admit_to_icu'].std():0.1f}\")\n",
    "print(f\"25th percentile:{notes_df['admit_to_icu'].quantile(0.25):0.1f}\")\n",
    "print(f\"75th percentile:{notes_df['admit_to_icu'].quantile(0.75):0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:35:04.927043Z",
     "start_time": "2019-11-08T11:35:04.909595Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Average Number of clinical notes per encounter for model cohort: {(len(model_notes_df)/model_notes_df['hadm_id'].nunique()):0.1f}\")\n",
    "print(f\"Average Number of clinical notes per encounter for notes cohort: {(len(notes_df)/notes_df['hadm_id'].nunique()):0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:35:05.090050Z",
     "start_time": "2019-11-08T11:35:05.065585Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Clinical Note Length for model cohort:\")\n",
    "print(f\"Mean:{model_notes_df['note_len'].mean():0.1f}\")\n",
    "print(f\"STD:{model_notes_df['note_len'].std():0.1f}\")\n",
    "print(f\"25th percentile:{model_notes_df['note_len'].quantile(0.25):0.1f}\")\n",
    "print(f\"75th percentile:{model_notes_df['note_len'].quantile(0.75):0.1f}\")\n",
    "print()\n",
    "print(\"Clinical Note Length for notes cohort:\")\n",
    "print(f\"Mean:{notes_df['note_len'].mean():0.1f}\")\n",
    "print(f\"STD:{notes_df['note_len'].std():0.1f}\")\n",
    "print(f\"25th percentile:{notes_df['note_len'].quantile(0.25):0.1f}\")\n",
    "print(f\"75th percentile:{notes_df['note_len'].quantile(0.75):0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:35:06.479779Z",
     "start_time": "2019-11-08T11:35:06.449176Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Note distribution by category in model cohort:\")\n",
    "g = pd.DataFrame(model_notes_df.groupby('category').size()).reset_index()\n",
    "g.columns = ['category', 'count']\n",
    "g['pct'] = np.round((g['count']/g['count'].sum() * 100), 1)\n",
    "print(g)\n",
    "print()\n",
    "print(\"Note distribution by category in notes cohort:\")\n",
    "g = pd.DataFrame(notes_df.groupby('category').size()).reset_index()\n",
    "g.columns = ['category', 'count']\n",
    "g['pct'] = np.round((g['count']/g['count'].sum() * 100), 1)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Notes Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:49:29.411016Z",
     "start_time": "2019-11-08T11:49:28.286327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cohort = 'notes_all'\n",
    "notes_df = pd.read_csv(path/f'{cohort}_proc.csv', parse_dates=['intime', 'admittime', 'ne_charttime'])\n",
    "\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:49:30.079479Z",
     "start_time": "2019-11-08T11:49:29.412776Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note length distribution\n",
    "fig, ax = plt.subplots(figsize=(11, 8))\n",
    "sns.distplot(notes_df['note_len'], kde=False, ax=ax, bins=100)\n",
    "ax.set_xlim(0, 10000)\n",
    "ax.set_xlabel('Length of Note (characters)')\n",
    "ax.set_ylabel('# notes')\n",
    "\n",
    "if save:\n",
    "  fig.savefig(figdir/f'{cohort}_note_len_dist.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:49:30.709041Z",
     "start_time": "2019-11-08T11:49:30.081827Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note distribution over days before ICU admission binned to 15 days\n",
    "plot_df = notes_df[['admit_to_icu']]\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.distplot(plot_df, kde=False, ax=ax, bins=80)\n",
    "ax.set_xlabel('Time to ICU admission (days)')\n",
    "ax.set_ylabel('# notes')\n",
    "ax.set_xlim(0, 70)\n",
    "\n",
    "if save:\n",
    "  fig.savefig(figdir/f'{cohort}_admit_to_icu_dist.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T11:49:31.260714Z",
     "start_time": "2019-11-08T11:49:30.711313Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note distribution over days before ICU admission binned to 15 days\n",
    "intervals = ['-1 ≤ t ≤ 0']\n",
    "intervals += [f'-{i+1} ≤ t ≤ -{i}' for i in range(1, notes_df['interval'].max())]\n",
    "intervals.append(f\"t ≥ -{notes_df['interval'].max()}\")\n",
    "\n",
    "plot_df = pd.DataFrame(notes_df.loc[notes_df['interval'] != -1].groupby('interval').size(), columns=['n_notes']).reset_index(drop=True)\n",
    "plot_df['days'] = intervals\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "sns.barplot(x='days', y='n_notes', data=plot_df, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45, ha='right')\n",
    "ax.set_xlabel('Time to ICU admission (days)')\n",
    "ax.set_ylabel('# notes')\n",
    "for index, row in plot_df.iterrows():\n",
    "    ax.text(index, row['n_notes'], str(row['n_notes']), color='black', ha='center', va='bottom')\n",
    "\n",
    "if save:\n",
    "  fig.savefig(figdir/f'{cohort}_admit_to_icu_binned_dist.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T12:47:22.475327Z",
     "start_time": "2019-11-08T12:47:17.467891Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note distribution over days before ICU admission by Category  binned to 15 days\n",
    "def plot_intervals(ax, df, cat):\n",
    "  sns.barplot(x='days', y='n_notes', data=df, ax=ax)\n",
    "  ax.set_xticklabels(ax.get_xticklabels(),rotation=45, ha='right')\n",
    "  ax.set_xlabel('')\n",
    "  ax.set_ylabel('')\n",
    "  ax.set_title(f\"Note Category: {cat}\\n# notes: {df['n_notes'].sum()}\")   \n",
    "\n",
    "  for index, (_, row) in enumerate(df.iterrows()):\n",
    "      ax.text(index, row['n_notes'], str(row['n_notes']), color='black', ha='center', va='bottom') \n",
    "\n",
    "plot_df = pd.DataFrame(notes_df.groupby(['category', 'interval']).size(), columns=['n_notes'])\n",
    "plot_df.reset_index(inplace=True)\n",
    "plot_df['days'] = plot_df['interval'].apply(lambda x: intervals[x])\n",
    "plot_df.drop(['interval'], inplace=True, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(4, 3, figsize=(20, 25))\n",
    "plot_intervals(ax[0][0], plot_df.loc[plot_df['category'] == 'Case Management ', ['n_notes', 'days']], 'Case Management')\n",
    "plot_intervals(ax[0][1], plot_df.loc[plot_df['category'] == 'Consult', ['n_notes', 'days']], 'Consult')\n",
    "plot_intervals(ax[0][2], plot_df.loc[plot_df['category'] == 'General', ['n_notes', 'days']], 'General')\n",
    "               \n",
    "plot_intervals(ax[1][0], plot_df.loc[plot_df['category'] == 'Nursing', ['n_notes', 'days']], 'Nursing')\n",
    "plot_intervals(ax[1][1], plot_df.loc[plot_df['category'] == 'Nursing/other', ['n_notes', 'days']], 'Nursing/other')\n",
    "plot_intervals(ax[1][2], plot_df.loc[plot_df['category'] == 'Nutrition', ['n_notes', 'days']], 'Nutrition')\n",
    "\n",
    "plot_intervals(ax[2][0], plot_df.loc[plot_df['category'] == 'Pharmacy', ['n_notes', 'days']], 'Pharmacy')\n",
    "plot_intervals(ax[2][1], plot_df.loc[plot_df['category'] == 'Physician ', ['n_notes', 'days',]], 'Physician')\n",
    "plot_intervals(ax[2][2], plot_df.loc[plot_df['category'] == 'Radiology', ['n_notes', 'days']], 'Radiology')\n",
    "               \n",
    "plot_intervals(ax[3][0], plot_df.loc[plot_df['category'] == 'Rehab Services', ['n_notes', 'days']], 'Rehab Services')\n",
    "plot_intervals(ax[3][1], plot_df.loc[plot_df['category'] == 'Respiratory ', ['n_notes', 'days']], 'Respiratory')\n",
    "plot_intervals(ax[3][2], plot_df.loc[plot_df['category'] == 'Social Work', ['n_notes', 'days']], 'Social Work')\n",
    "\n",
    "fig.text(0.5, 0.09, 'Time to ICU admission (days)', ha='center')\n",
    "fig.text(0.08, 0.5, '# notes', va='center', rotation='vertical')\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "               \n",
    "if save:               \n",
    "  fig.savefig(figdir/f'{cohort}_admit_to_icu_cat_binned_dist.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T14:25:52.503649Z",
     "start_time": "2019-11-08T14:25:51.885341Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Histogram of time between note charttime and ICU admittime\n",
    "plot_df = notes_df[['category', 'note_to_icu']]\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.distplot(plot_df['note_to_icu'], kde=False, ax=ax, bins=80)\n",
    "ax.set_xlabel('Note Charttime to ICU Admittime (days)')\n",
    "ax.set_ylabel('# notes')\n",
    "ax.set_xlim(0, 60)\n",
    "\n",
    "if save:\n",
    "  fig.savefig(figdir/f'{cohort}_note_to_icu_dist.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T14:26:18.244019Z",
     "start_time": "2019-11-08T14:26:13.786692Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram of time between note charttime and ICU admittime by Category\n",
    "def plot_period(ax, df, cat):\n",
    "  sns.distplot(df, kde=False, ax=ax, bins=10)\n",
    "  ax.set_xlabel('')\n",
    "  ax.set_ylabel('')\n",
    "  ax.set_title(f\"Note Category: {cat}\")\n",
    "\n",
    "fig, ax = plt.subplots(4, 3, figsize=(20, 25))\n",
    "plot_period(ax[0][0], plot_df.loc[plot_df['category'] == 'Case Management ', ['note_to_icu']], 'Case Management')\n",
    "plot_period(ax[0][1], plot_df.loc[plot_df['category'] == 'Consult', ['note_to_icu']], 'Consult')\n",
    "plot_period(ax[0][2], plot_df.loc[plot_df['category'] == 'General', ['note_to_icu']], 'General')\n",
    "\n",
    "plot_period(ax[1][0], plot_df.loc[plot_df['category'] == 'Nursing', ['note_to_icu']], 'Nursing')\n",
    "plot_period(ax[1][1], plot_df.loc[plot_df['category'] == 'Nursing/other', ['note_to_icu']], 'Nursing/other')\n",
    "plot_period(ax[1][2], plot_df.loc[plot_df['category'] == 'Nutrition', ['note_to_icu']], 'Nutrition')\n",
    "\n",
    "plot_period(ax[2][0], plot_df.loc[plot_df['category'] == 'Pharmacy', ['note_to_icu']], 'Pharmacy')\n",
    "plot_period(ax[2][1], plot_df.loc[plot_df['category'] == 'Physician ', ['note_to_icu',]], 'Physician')\n",
    "plot_period(ax[2][2], plot_df.loc[plot_df['category'] == 'Radiology', ['note_to_icu']], 'Radiology')\n",
    "\n",
    "plot_period(ax[3][0], plot_df.loc[plot_df['category'] == 'Rehab Services', ['note_to_icu']], 'Rehab Services')\n",
    "plot_period(ax[3][1], plot_df.loc[plot_df['category'] == 'Respiratory ', ['note_to_icu']], 'Respiratory')\n",
    "plot_period(ax[3][2], plot_df.loc[plot_df['category'] == 'Social Work', ['note_to_icu']], 'Social Work')\n",
    "\n",
    "fig.text(0.5, 0.1, 'Note Charttime to ICU Admittime (days)', ha='center')\n",
    "fig.text(0.08, 0.5, '# notes', va='center', rotation='vertical')\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.1)\n",
    "\n",
    "if save:\n",
    "  fig.savefig(figdir/f'{cohort}_note_to_icu_cat_dist.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T15:03:10.440104Z",
     "start_time": "2019-11-08T15:03:10.159215Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "desc = ['Unused', 'Delayed ICU Admission', 'Imminent ICU Admission']\n",
    "\n",
    "p = pd.DataFrame(notes_df.groupby(['imi_adm_label']).size(), columns=['n_notes']).reset_index()\n",
    "# p1 = pd.DataFrame(notes_df.groupby(['imi_adm_label']).size(), columns=['n_notes']).reset_index()\n",
    "# p2 = notes_df.groupby(['imi_adm_label'])['hadm_id'].nunique().reset_index()\n",
    "\n",
    "# p = p1.merge(p2, on=['imi_adm_label'])\n",
    "p['imi_adm_label'] = desc\n",
    "p = p.reindex([2, 1, 0])\n",
    "# p.reset_index(inplace=True, drop=True)\n",
    "\n",
    "plot_df = p.copy()\n",
    "plot_df.rename(columns={'hadm_id':'# Encounters', 'n_notes':'# Notes'}, inplace=True)\n",
    "plot_df = pd.melt(plot_df, id_vars='imi_adm_label', var_name='Legend', value_name='counts')\n",
    "\n",
    "plot_df\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 8))\n",
    "sns.barplot(x='imi_adm_label', y='counts', data=plot_df, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), ha='center')\n",
    "ax.set_xlabel('Class Label')\n",
    "ax.set_ylabel('# notes')\n",
    "\n",
    "for index, row in plot_df.iterrows():\n",
    "#     if index < len(plot_df)//2:\n",
    "        ax.text(index+0.06, row['counts'], str(row['counts']), color='black', ha='right', va='bottom')\n",
    "#     else:\n",
    "#         ax.text(index % (len(plot_df)//2), row['counts'], str(row['counts']), color='black', ha='right', va='bottom')\n",
    "\n",
    "if save:\n",
    "  fig.savefig(figdir/f'{cohort}_note_class_dist.pdf', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
