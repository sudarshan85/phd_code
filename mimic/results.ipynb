{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Models using only MIMIC Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:39:42.799237Z",
     "start_time": "2019-12-19T19:39:41.287743Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from utils.metrics import BinaryAvgMetrics\n",
    "from utils.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:39:42.821525Z",
     "start_time": "2019-12-19T19:39:42.801124Z"
    }
   },
   "outputs": [],
   "source": [
    "from lr.args import args as lr_args\n",
    "from rf.args import args as rf_args\n",
    "from gbm.args import args as gbm_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:39:42.841909Z",
     "start_time": "2019-12-19T19:39:42.823654Z"
    }
   },
   "outputs": [],
   "source": [
    "s_thresh = {\n",
    "  'LR': lr_args.structured_threshold,\n",
    "  'RF': rf_args.structured_threshold,\n",
    "  'GBM': gbm_args.structured_threshold,\n",
    "}\n",
    "\n",
    "u_thresh = {\n",
    "  'LR': lr_args.unstructured_threshold,\n",
    "  'RF': rf_args.unstructured_threshold,\n",
    "  'GBM': gbm_args.unstructured_threshold,\n",
    "}\n",
    "\n",
    "mm_thresh = {\n",
    "  'LR': lr_args.mm_threshold,\n",
    "  'RF': rf_args.mm_threshold,\n",
    "  'GBM': gbm_args.mm_threshold,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:39:42.860443Z",
     "start_time": "2019-12-19T19:39:42.843157Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "workdir = path/'workdir/'\n",
    "figdir = workdir/'figures'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:39:42.883166Z",
     "start_time": "2019-12-19T19:39:42.862187Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ensemble(ensembles, thresh, bams):  \n",
    "  outputs = {}\n",
    "  for ens_model in ensembles:\n",
    "    key = '-'.join(ens_model)\n",
    "    targs = bams[ens_model[0]].targs\n",
    "    avg_thresh = np.array([thresh[model] for model in ens_model]).mean()\n",
    "    max_thresh = max([thresh[model] for model in ens_model])\n",
    "    probs = []\n",
    "    for i in range(len(targs)):\n",
    "      prob = []\n",
    "      for model in ens_model:\n",
    "        prob.append(bams[model].pos_probs[i])\n",
    "      probs.append(np.stack(prob))\n",
    "\n",
    "    avg_probs = [probs.mean(axis=0) for probs in probs]\n",
    "    max_probs = [probs.max(axis=0) for probs in probs]\n",
    "\n",
    "    avg_preds = [(probs > avg_thresh).astype(np.int64) for probs in avg_probs]\n",
    "    max_preds = [(probs > max_thresh).astype(np.int64) for probs in max_probs]\n",
    "    outputs[f'AVG-{key}'] = (targs, avg_preds, avg_probs, avg_thresh)\n",
    "    outputs[f'MAX-{key}'] = (targs, max_preds, max_probs, max_thresh)\n",
    "    \n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:39:42.904599Z",
     "start_time": "2019-12-19T19:39:42.884234Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_ttest(bams, model1, model2, metric):  \n",
    "  if metric == 'sensitivity':\n",
    "    x1 = bams[model1].sensitivities()\n",
    "    x2 = bams[model2].sensitivities()\n",
    "  elif metric == 'specificity':\n",
    "    x1 = bams[model1].specificities()\n",
    "    x2 = bams[model2].specificities()\n",
    "  elif metric == 'ppv':\n",
    "    x1 = bams[model1].ppvs()\n",
    "    x2 = bams[model2].ppvs()\n",
    "  elif metric == 'auroc':\n",
    "    x1 = bams[model1].aurocs()\n",
    "    x2 = bams[model2].aurocs()\n",
    "  elif metric == 'npv':\n",
    "    x1 = bams[model1].npvs()\n",
    "    x2 = bams[model2].npvs()\n",
    "  elif metric == 'f1':    \n",
    "    x1 = bams[model1].f1s()\n",
    "    x2 = bams[model2].f1s()\n",
    "\n",
    "  t, p = stats.ttest_ind(x1, x2)\n",
    "  return np.round(t, 2), max(np.round(p, 2), 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:41:47.749463Z",
     "start_time": "2019-12-19T19:41:47.701419Z"
    }
   },
   "outputs": [],
   "source": [
    "subset = 'u+s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:41:48.831865Z",
     "start_time": "2019-12-19T19:41:47.752326Z"
    }
   },
   "outputs": [],
   "source": [
    "if subset == 's':\n",
    "  thresh = s_thresh\n",
    "elif subset == 'u':\n",
    "  thresh = u_thresh\n",
    "elif subset == 'u+s':\n",
    "  thresh = mm_thresh\n",
    "\n",
    "models = ['LR', 'RF', 'GBM']\n",
    "bams = {}\n",
    "\n",
    "for model in models:\n",
    "  with open(workdir/model.lower()/f'{subset}_preds.pkl', 'rb') as f:\n",
    "    targs = pickle.load(f)\n",
    "    probs = pickle.load(f)\n",
    "    preds = pickle.load(f)\n",
    "  bams[model] = BinaryAvgMetrics(targs, preds, [prob[:, 1] for prob in probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:41:48.853801Z",
     "start_time": "2019-12-19T19:41:48.833688Z"
    }
   },
   "outputs": [],
   "source": [
    "# ens_models = [\n",
    "#   ['lr', 'rf'],\n",
    "#   ['lr', 'gbm'],\n",
    "#   ['rf', 'gbm'],  \n",
    "#   ['lr', 'rf', 'gbm'],\n",
    "# ]\n",
    "\n",
    "ens_models = [m for m in sum([list(map(list, combinations(models, i))) for i in range(len(models) + 1)], []) if len(m) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:41:51.486772Z",
     "start_time": "2019-12-19T19:41:48.855192Z"
    }
   },
   "outputs": [],
   "source": [
    "ensembles = get_ensemble(ens_models, thresh, bams)\n",
    "\n",
    "for model, vals in ensembles.items():\n",
    "  bams[model] = BinaryAvgMetrics(*vals[:-1])  \n",
    "\n",
    "# remove the pair maxes\n",
    "bams.pop('MAX-LR-RF')\n",
    "bams.pop('MAX-LR-GBM')\n",
    "bams.pop('MAX-RF-GBM')\n",
    "bams['AVG-ALL'] = bams.pop('AVG-LR-RF-GBM')\n",
    "bams['MAX-ALL'] = bams.pop('MAX-LR-RF-GBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:41:57.924925Z",
     "start_time": "2019-12-19T19:41:51.488602Z"
    }
   },
   "outputs": [],
   "source": [
    "final_metrics = {}\n",
    "\n",
    "for key in bams.keys():\n",
    "  final_metrics[key] = []\n",
    "  for i in range(len(bams[key].get_main_avg_metrics())):\n",
    "    final_metrics[key].append(bams[key].get_main_avg_metrics().iloc[i]['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:41:57.948628Z",
     "start_time": "2019-12-19T19:41:57.926411Z"
    }
   },
   "outputs": [],
   "source": [
    "final_metrics = pd.DataFrame(final_metrics, index=['sensitivity', 'specificity', 'ppv', 'auroc']).transpose()\n",
    "\n",
    "best_models = pd.DataFrame([(final_metrics[metric].idxmax(), final_metrics[metric].max()) for metric in final_metrics], columns=['model', 'value'], index=['sensitivity', 'specificity', 'ppv', 'auroc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:41:57.967915Z",
     "start_time": "2019-12-19T19:41:57.949705Z"
    }
   },
   "outputs": [],
   "source": [
    "models = list(final_metrics.index)\n",
    "metrics = list(final_metrics.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:42:06.931967Z",
     "start_time": "2019-12-19T19:41:57.969776Z"
    }
   },
   "outputs": [],
   "source": [
    "ttests = {}\n",
    "\n",
    "for m1, m2 in combinations(models, 2):  \n",
    "  ttests[f'{m1}:{m2}'] = {}\n",
    "  for metric in metrics:\n",
    "    ttests[f'{m1}:{m2}'][metric] = do_ttest(bams, m1, m2, metric)\n",
    "\n",
    "ttests = pd.DataFrame(ttests).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:42:07.359182Z",
     "start_time": "2019-12-19T19:42:06.933616Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(bams, open(workdir/f'{subset}_bams.pkl', 'wb'))\n",
    "final_metrics.to_csv(workdir/f'{subset}_metrics.csv', float_format='%.3f')\n",
    "best_models.to_csv(workdir/f'{subset}_best_models.csv', float_format='%.3f')\n",
    "ttests.to_csv(workdir/f'{subset}_ttests.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:42:26.522903Z",
     "start_time": "2019-12-19T19:42:26.298528Z"
    }
   },
   "outputs": [],
   "source": [
    "subsets = ['s', 'u', 'u+s']\n",
    "ptr = iter(subsets)\n",
    "\n",
    "best_all = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:43:31.073776Z",
     "start_time": "2019-12-19T19:43:31.026234Z"
    }
   },
   "outputs": [],
   "source": [
    "subset = next(ptr)\n",
    "best_all[subset] = {}\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:43:31.239947Z",
     "start_time": "2019-12-19T19:43:31.076635Z"
    }
   },
   "outputs": [],
   "source": [
    "bams = pickle.load(open(workdir/f'{subset}_bams.pkl', 'rb'))\n",
    "final_metrics = pd.read_csv(workdir/f'{subset}_metrics.csv', index_col=0)\n",
    "best_models = pd.read_csv(workdir/f'{subset}_best_models.csv', index_col=0)\n",
    "ttests = pd.read_csv(workdir/f'{subset}_ttests.csv', index_col=0)\n",
    "\n",
    "best_models.reset_index(inplace=True)\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:43:31.290985Z",
     "start_time": "2019-12-19T19:43:31.269666Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, row in best_models.iterrows():\n",
    "  if i > 3: break\n",
    "  best_all[subset][row['index']] = (row['model'], row['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best ttests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:05:12.848649Z",
     "start_time": "2019-12-19T20:05:12.245579Z"
    }
   },
   "outputs": [],
   "source": [
    "s_bams = pickle.load(open(workdir/f's_bams.pkl', 'rb'))\n",
    "u_bams = pickle.load(open(workdir/f'u_bams.pkl', 'rb'))\n",
    "us_bams = pickle.load(open(workdir/f'u+s_bams.pkl', 'rb'))\n",
    "\n",
    "mets = ['sensitivity', 'specificity', 'ppv', 'auroc']\n",
    "itr = iter(mets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:12:18.411392Z",
     "start_time": "2019-12-19T20:12:17.829728Z"
    }
   },
   "outputs": [],
   "source": [
    "met = next(itr)\n",
    "print(met)\n",
    "\n",
    "if met == 'sensitivity':\n",
    "  s_met = s_bams[best_all['s'][met][0]].sensitivities()\n",
    "  u_met = u_bams[best_all['u'][met][0]].sensitivities()\n",
    "  us_met = us_bams[best_all['u+s'][met][0]].sensitivities()\n",
    "elif met == 'specificity':\n",
    "  s_met = s_bams[best_all['s'][met][0]].specificities()\n",
    "  u_met = u_bams[best_all['u'][met][0]].specificities()\n",
    "  us_met = us_bams[best_all['u+s'][met][0]].specificities()\n",
    "if met == 'ppv':\n",
    "  s_met = s_bams[best_all['s'][met][0]].ppvs()\n",
    "  u_met = u_bams[best_all['u'][met][0]].ppvs()\n",
    "  us_met = us_bams[best_all['u+s'][met][0]].ppvs()\n",
    "if met == 'auroc':\n",
    "  s_met = s_bams[best_all['s'][met][0]].aurocs()\n",
    "  u_met = u_bams[best_all['u'][met][0]].aurocs()\n",
    "  us_met = us_bams[best_all['u+s'][met][0]].aurocs()\n",
    "\n",
    "_, p_s_u = stats.ttest_ind(s_met, u_met)\n",
    "_, p_u_us = stats.ttest_ind(u_met, us_met)\n",
    "_, p_s_us = stats.ttest_ind(s_met, us_met)\n",
    "\n",
    "print(f\"p (structured - unstructured): {max(p_s_u, 0.001)}\")\n",
    "print(f\"p (unstructured - mm): {max(p_u_us, 0.001)}\")\n",
    "print(f\"p (structured - mm): {max(p_s_us, 0.001)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:17:32.717356Z",
     "start_time": "2019-12-19T20:17:32.512433Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:19:34.640854Z",
     "start_time": "2019-12-19T20:19:34.291971Z"
    }
   },
   "outputs": [],
   "source": [
    "subset, label = 'u+s','Notes and Vitals (U+S)'\n",
    "\n",
    "bams = pickle.load(open(workdir/f'{subset}_bams.pkl', 'rb'))\n",
    "final_metrics = pd.read_csv(workdir/f'{subset}_metrics.csv', index_col=0)\n",
    "best_models = pd.read_csv(workdir/f'{subset}_best_models.csv', index_col=0)\n",
    "ttests = pd.read_csv(workdir/f'{subset}_ttests.csv', index_col=0)\n",
    "\n",
    "itr = iter(bams.keys())\n",
    "bams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:19:36.668466Z",
     "start_time": "2019-12-19T20:19:35.313398Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "for md in itr:\n",
    "  df = pd.DataFrame()\n",
    "  for k, m in bams[md].yield_metrics():\n",
    "    df[k] = m\n",
    "  df['Model'] = md\n",
    "  cols = list(df.columns)\n",
    "  cols = [cols[-1]] + cols[:-1]\n",
    "  df = df[cols]\n",
    "  metrics[md] = df\n",
    "\n",
    "plot_df = pd.concat(metrics.values())\n",
    "plot_df['Label'] = label\n",
    "plot_dfs.append(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:19:42.056151Z",
     "start_time": "2019-12-19T20:19:41.993275Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_df = pd.concat(plot_dfs)\n",
    "plot_df[['Sensitivity', 'Specificity', 'PPV', 'AUC']] = plot_df[['Sensitivity', 'Specificity', 'PPV', 'AUC']] * 100\n",
    "plot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:33:06.712436Z",
     "start_time": "2019-12-19T20:33:06.565674Z"
    }
   },
   "outputs": [],
   "source": [
    "mets = ['Sensitivity', 'Specificity', 'PPV', 'AUC']\n",
    "itr = iter(mets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:45:19.960943Z",
     "start_time": "2019-12-19T20:45:19.347450Z"
    }
   },
   "outputs": [],
   "source": [
    "met = next(itr)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "sns.boxplot(x='Model', y=met, hue='Label', data=plot_df, ax=ax)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[0:], labels=labels[0:])\n",
    "# for i in range(7): plt.axvline(x=i+0.5, ls='-.', color='black')\n",
    "ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:45:20.059376Z",
     "start_time": "2019-12-19T20:45:19.962213Z"
    }
   },
   "outputs": [],
   "source": [
    "fig.savefig(figdir/f'{met.lower()}_box_plot.pdf', dpi=300, box_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:45:30.242143Z",
     "start_time": "2019-12-19T20:45:30.190420Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_tprs(bams, base_fpr):\n",
    "  mean_tprs = {}  \n",
    "  for model, bam in bams.items():\n",
    "    tprs = []  \n",
    "    for i, (targs, probs) in enumerate(zip(bam.targs, bam.pos_probs)):\n",
    "      fpr, tpr, _ = roc_curve(targs, probs)\n",
    "      tpr = interp(base_fpr, fpr, tpr)\n",
    "      tpr[0] = 0.0\n",
    "      tprs.append(tpr)\n",
    "\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tprs[model] = tprs.mean(axis=0)\n",
    "    \n",
    "  return mean_tprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:51:25.928272Z",
     "start_time": "2019-12-19T20:51:25.740174Z"
    }
   },
   "outputs": [],
   "source": [
    "subsets = ['s', 'u', 'u+s']\n",
    "itr = iter(subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:51:26.093966Z",
     "start_time": "2019-12-19T20:51:25.929816Z"
    }
   },
   "outputs": [],
   "source": [
    "subset = next(itr)\n",
    "\n",
    "bams = pickle.load(open(workdir/f'{subset}_bams.pkl', 'rb'))\n",
    "final_metrics = pd.read_csv(workdir/f'{subset}_metrics.csv', index_col=0)\n",
    "best_models = pd.read_csv(workdir/f'{subset}_best_models.csv', index_col=0)\n",
    "ttests = pd.read_csv(workdir/f'{subset}_ttests.csv', index_col=0)\n",
    "\n",
    "dess = [None, 'avg_', 'max_', 'all_']\n",
    "itr2 = iter(dess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:51:38.969672Z",
     "start_time": "2019-12-19T20:51:38.255391Z"
    }
   },
   "outputs": [],
   "source": [
    "des = next(itr2)\n",
    "\n",
    "if not des:\n",
    "  plot_bams = {k: bams[k] for k in bams.keys() if '-' not in k}\n",
    "  des = ''  \n",
    "  names = plot_bams.keys()\n",
    "  aucs = [model.auroc_avg() for _, model in plot_bams.items()]\n",
    "  legends = [f'{model} ({auc})' for model, auc in zip(names, aucs)]\n",
    "elif des == 'avg_':\n",
    "  plot_bams = {k: bams[k] for k in bams.keys() if 'AVG' in k}\n",
    "  names = [name[4:] for name in plot_bams.keys()]\n",
    "  aucs = [model.auroc_avg() for _, model in plot_bams.items()]\n",
    "  legends = [f'{model} ({auc})' for model, auc in zip(names, aucs)]  \n",
    "elif des == 'max_':\n",
    "  plot_bams = {k: bams[k] for k in bams.keys() if 'MAX' in k}\n",
    "  names = [name[4:] for name in plot_bams.keys()]\n",
    "  aucs = [model.auroc_avg() for _, model in plot_bams.items()]\n",
    "  legends = [f'{model} ({auc})' for model, auc in zip(names, aucs)]  \n",
    "elif des == 'all_':\n",
    "  plot_bams = bams\n",
    "  names = plot_bams.keys()\n",
    "  aucs = [model.auroc_avg() for _, model in plot_bams.items()]\n",
    "  legends = [f'{model} ({auc})' for model, auc in zip(names, aucs)]\n",
    "  \n",
    "legends  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:51:39.560362Z",
     "start_time": "2019-12-19T20:51:38.971077Z"
    }
   },
   "outputs": [],
   "source": [
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tprs = get_mean_tprs(plot_bams, base_fpr)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11, 8))\n",
    "for i, (model, mean_tpr) in enumerate(mean_tprs.items()):\n",
    "  ax.plot(base_fpr, mean_tpr)\n",
    "ax.plot([0, 1], [0, 1], linestyle=':')  \n",
    "ax.grid(b=True, which='major', color='#d3d3d3', linewidth=1.0)\n",
    "ax.grid(b=True, which='minor', color='#d3d3d3', linewidth=0.5)\n",
    "ax.set_ylabel('Sensitivity')\n",
    "ax.set_xlabel('1 - Specificity')\n",
    "ax.legend(legends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:51:39.631346Z",
     "start_time": "2019-12-19T20:51:39.561919Z"
    }
   },
   "outputs": [],
   "source": [
    "fig.savefig(figdir/f'{subset}_{des}mean_auc.pdf', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
