{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imminent ICU Admission Classifier with MLH Notes only using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T17:53:50.273165Z",
     "start_time": "2019-12-20T17:53:48.200297Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import pickle\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scikitplot.metrics import *\n",
    "\n",
    "from utils.data_utils import set_group_splits\n",
    "from utils.metrics import BinaryAvgMetrics, get_best_model\n",
    "from utils.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T17:53:50.307291Z",
     "start_time": "2019-12-20T17:53:50.275752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': PosixPath('../data'),\n",
       " 'workdir': PosixPath('../data/workdir'),\n",
       " 'figdir': PosixPath('../data/figures'),\n",
       " 'dataset_csv': PosixPath('../data/unstructured_proc.csv'),\n",
       " 'threshold': 0.31}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from args import args\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T17:53:54.248629Z",
     "start_time": "2019-12-20T17:53:50.309273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116400, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 643\n",
    "notes_df = pd.read_csv(args.dataset_csv, usecols=['hadm_id', 'note', 'imi_adm_label'])\n",
    "notes_df = notes_df[notes_df['imi_adm_label'] != -1].reset_index(drop=True)\n",
    "notes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T17:53:54.310849Z",
     "start_time": "2019-12-20T17:53:54.251730Z"
    }
   },
   "outputs": [],
   "source": [
    "save = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T17:53:54.353871Z",
     "start_time": "2019-12-20T17:53:54.313594Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cloud(scores, idx2tok, n_tokens=50, min_len=4):\n",
    "  sorted_idxs = np.argsort(scores)  \n",
    "  p = re.compile('^[a-z\\s]+$')\n",
    "  tokens = []\n",
    "  trim_scores = []\n",
    "\n",
    "  for idx in sorted_idxs:\n",
    "    token = idx2tok[idx].lower()\n",
    "    if len(token) > min_len and p.match(token):\n",
    "      tokens.append(token)\n",
    "      trim_scores.append(scores[idx] * -1)\n",
    "      \n",
    "  pos_dict = {k: v for k, v in zip(tokens[:n_tokens], trim_scores[:n_tokens])}\n",
    "  neg_dict = {k: v for k, v in zip(tokens[-n_tokens:], trim_scores[-n_tokens:])}\n",
    "  \n",
    "  pos_cloud = WordCloud(width=400, height=400, background_color='white', max_font_size=60, relative_scaling=0.5).generate_from_frequencies(pos_dict)\n",
    "  neg_cloud = WordCloud(width=400, height=400, background_color='white', max_font_size=60, relative_scaling=0.5).generate_from_frequencies(neg_dict)\n",
    "  \n",
    "  return pos_cloud, neg_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T17:53:55.299636Z",
     "start_time": "2019-12-20T17:53:55.083473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence of positive class in training set:3.3%\n",
      "Prevalence of positive class in test set:3.6%\n"
     ]
    }
   ],
   "source": [
    "df = set_group_splits(notes_df.copy(), group_col='hadm_id', seed=seed)\n",
    "\n",
    "train_df = df[df['split'] == 'train'][['note', 'imi_adm_label']]\n",
    "test_df = df[df['split'] == 'test'][['note', 'imi_adm_label']]\n",
    "\n",
    "g = train_df.groupby(['imi_adm_label']).size().to_numpy()\n",
    "print(f\"Prevalence of positive class in training set:{(g[1]/g.sum())*100:0.1f}%\")\n",
    "g = test_df.groupby(['imi_adm_label']).size().to_numpy()\n",
    "print(f\"Prevalence of positive class in test set:{(g[1]/g.sum())*100:0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T01:23:48.398331Z",
     "start_time": "2019-11-27T01:23:46.953364Z"
    }
   },
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=60_000)\n",
    "# x_train = vectorizer.fit_transform(train_df['note'])\n",
    "# x_test = vectorizer.transform(test_df['note'])\n",
    "\n",
    "# with open(args.workdir/f'vectordir/default_bi_643.pkl', 'wb') as f:\n",
    "#   pickle.dump(vectorizer, f)\n",
    "#   pickle.dump(x_train, f)\n",
    "#   pickle.dump(x_test, f)\n",
    "\n",
    "with open(args.workdir/f'vectordir/default_bi_643.pkl', 'rb') as f:\n",
    "  vectorizer = pickle.load(f)\n",
    "  x_train = pickle.load(f)\n",
    "  x_test = pickle.load(f)\n",
    "  \n",
    "y_train,y_test = train_df['imi_adm_label'], test_df['imi_adm_label']\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T01:24:30.709893Z",
     "start_time": "2019-11-27T01:23:49.217258Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight='balanced')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "prob = clf.predict_proba(x_test)\n",
    "pos_prob = prob[:, 1]\n",
    "\n",
    "labels = ['Delayed', 'Imminent']\n",
    "label_test = [labels[i] for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T01:24:31.192602Z",
     "start_time": "2019-11-27T01:24:30.712070Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plot_roc(label_test, prob, title='', ax=ax)\n",
    "ax.set_xlabel('1 - Specificity')\n",
    "ax.set_ylabel('Sensitivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T01:24:32.509773Z",
     "start_time": "2019-11-27T01:24:31.194575Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "best_threshold = plot_thresh_metric(ax, y_test, pos_prob, lower=0.1, upper=0.81, n_vals=100)\n",
    "ax.text(0.71, ax.get_ylim()[1] * 0.9, f'Optimum Threshold = {best_threshold[0]}', fontsize=12, color='b')\n",
    "print(best_threshold)\n",
    "\n",
    "if save:\n",
    "  fig.savefig(args.figdir/f'{args.model}_threshold_guide.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T01:24:33.829527Z",
     "start_time": "2019-11-27T01:24:32.511415Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plot_thresh_range(ax, y_test, pos_prob, lower=0.1, upper=0.81, n_vals=100)\n",
    "\n",
    "if save:\n",
    "  fig.savefig(args.figdir/f'{args.model}_metrics_vary.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T01:24:33.877720Z",
     "start_time": "2019-11-27T01:24:33.831101Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.31\n",
    "pred = (pos_prob > threshold).astype(np.int64)\n",
    "label_preds = [labels[i] for i in pred]\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "tn,fp,fn,tp = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "f1 = (2*ppv*sensitivity)/(ppv+sensitivity)\n",
    "auroc = roc_auc_score(y_test, pos_prob)\n",
    "\n",
    "d = {\n",
    "  'sensitivity': np.round(sensitivity, 3),\n",
    "  'specificity': np.round(specificity, 3),\n",
    "  'ppv': np.round(ppv, 3),\n",
    "  'npv': np.round(npv, 3),\n",
    "  'f1': np.round(f1, 3),\n",
    "  'auroc': np.round(auroc, 3),\n",
    "  'threshold': threshold,\n",
    "}\n",
    "metrics = pd.DataFrame(d.values(), index=d.keys(), columns=['Value'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T01:24:34.256727Z",
     "start_time": "2019-11-27T01:24:33.879086Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 8))\n",
    "plot_confusion_matrix(label_test, label_preds, x_tick_rotation=45, ax=ax, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T01:25:18.814493Z",
     "start_time": "2019-11-27T01:25:16.805605Z"
    }
   },
   "outputs": [],
   "source": [
    "idx2tok = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "pos_cloud, neg_cloud = compute_cloud(clf.coef_[0], idx2tok, n_tokens=250)\n",
    "ax[0].imshow(neg_cloud)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Delayed ICU Admission')\n",
    "ax[1].imshow(pos_cloud)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Imminent ICU Admission')\n",
    "\n",
    "if save:\n",
    "  fig.savefig(args.figdir/f'wordcloud.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T15:25:44.773046Z",
     "start_time": "2019-11-24T15:25:43.155806Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(args.workdir/f'{args.expt}_preds.pkl', 'rb') as f:\n",
    "  targs = pickle.load(f)\n",
    "  probs = pickle.load(f)\n",
    "  preds = pickle.load(f)\n",
    "\n",
    "bam = BinaryAvgMetrics(targs, preds, [prob[:, 1] for prob in probs])\n",
    "bam.get_avg_metrics(defn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T15:25:46.107192Z",
     "start_time": "2019-11-24T15:25:45.678017Z"
    }
   },
   "outputs": [],
   "source": [
    "bam.get_avg_metrics(conf=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T15:25:53.598233Z",
     "start_time": "2019-11-24T15:25:53.547822Z"
    }
   },
   "outputs": [],
   "source": [
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T15:25:54.971414Z",
     "start_time": "2019-11-24T15:25:54.370719Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plot_mean_roc(ax, bam.targs, probs)\n",
    "\n",
    "if save:\n",
    "  fig.savefig(args.figdir/f'{args.expt}_mean_roc.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T15:25:57.980637Z",
     "start_time": "2019-11-24T15:25:57.600819Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 8))\n",
    "plot_cm(ax, bam.cm_avg, ['Delayed', 'Imminent'])\n",
    "\n",
    "if save:\n",
    "  fig.savefig(args.figdir/f'{args.prefix}_mean_cm.pdf', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
